\subsection{Introduction:}
Over the years I have invested a significant amount of time developing scripts in R and Python for the processing of video game performance data, which I am rather proud of for the different features I have built in as well as the various statistics and graphs they produce. Though it is game performance data I most often work with, I had an idea and decided to apply the same skills to craft scripts for the collection and processing of thermal performance data for both CPUs and GPUs. In their original form, I used these scripts to write three articles: \href{http://www.overclockersclub.com/reviews/cpu_thermal_scripts}{CPU Thermal Testing Scripts Experiment}; \href{http://www.overclockersclub.com/reviews/graphite_pad_analysis}{Graphite Thermal Pad Analysis}; and \href{http://www.overclockersclub.com/reviews/gpu_thermal_scripts}{GPU Thermal Testing Scripts Experiment}. The purpose of this article is to go through the CPU thermal testing scripts in detail, and to have a good reason to review and revise the relevant scripts. Though the basic function of these scripts has not been significantly altered, I have reorganized the features and functions to make the addition of new CPU loads easier. At the same time I added support for \href{https://www.mersenne.org/}{Prime95} as another CPU test load, bringing the total to four different tests to load the processor.

The other software supported by and necessary for these scripts has not changed since the original articles linked to above. For loads there are \href{https://www.maxon.net/en-us/support/downloads/}{Cinebench R20 and R23}, \href{https://benchmarks.ul.com/3dmark}{3DMark Professional Edition}, and Prime95 while the software required is \href{https://www.r-project.org/}{R} with the \href{https://readr.tidyverse.org/}{readr}, \href{https://ggplot2.tidyverse.org/index.html}{ggplot2}, and \href{https://tidyr.tidyverse.org/}{tidyr} libraries, \href{https://www.python.org/}{Python} with its \href{https://pypi.org/project/psutil/}{psutil} and \href{https://pypi.org/project/py-cpuinfo/}{py-cpuinfo} modules (other modules are included with the install of Python though will still need to be loaded), and then the monitoring software that depends on the brand of CPU you have. For Intel the \href{https://software.intel.com/en-us/articles/intel-power-gadget}{Intel Power Gadget} is able to record all of the information necessary itself, while for AMD you need \href{https://developer.amd.com/amd-uprof/}{AMD μProf} and \href{https://www.techpowerup.com/gpuz/}{GPU-z}. AMD μProf is able to record many metrics, including per-thread frequency and per-core energy usage, but it does not consistently capture CPU temperature for my setup, which is why I use GPU-z, as it can capture and log CPU temperature. It should be noted that with the exception of 3DMark Professional Edition, all of this software is free and some of it is open source as well. (3DMark Professional Edition is the only version of this software that supports command line instructions, which are necessary for controlling it by scripts.)

Something very important that I only recently encountered is that a newer version of AMD μProf than I originally developed these scripts around has released and it has made some very significant changes. The arguments to launch it are different, the measurements it records have subtle but impactful differences, and it will now record CPU temperature on my test system, something it could not do originally. I have done my best to adapt the scripts to these changes, but not everything has an easy solution; specifically the different CLI arguments. As far as the CPU temperature, the measurements may include an offset AMD applied so the CPU reacts to heating a bit sooner and so that data might not be ideal to use. The data will be included for reference and experimentation, but go unused for any of the processing.

I said earlier that all of this effort is the result of an idea I had, but I have not properly addressed what this idea was. It was not just to have some means of collecting thermal performance data, but to capture data around it. A lot of times when I see a review or other analysis that considers thermal performance, the only information reported are summary statistics such as maximum temperature, average clock speed, and similar. Of course those values are important, but I was curious about more than these single points in time or expected values, and I wanted more types of measurements. Additionally, I wanted data from after the load ends, to see the cooldown behavior, and before to get a sense of the system's idle state. I consider this before or Warm-up data as I label it, to be quite important because it provides an idle temperature for the processor, and thus it is appropriate to compare the load temperature against. Additionally the Cooldown period, after the test period when the load is applied, allows us to see how effectively the processor is cooled off, as well as some relevant behaviors, such as the impact of Zero RPM modes.

I mentioned earlier that I have previously written articles concerning these scripts, and these articles do include statistics and graphs of data I recorded at the time. Rather than reuse any of that content though, I have recorded fresh data for these newer articles. (It also helps to get fresh data to ensure the scripts are working properly.) All of the data, regardless of the article, was captured in my test system with these components, unless otherwise noted:

\begin{itemize}
	\item	Processor: AMD Ryzen 7 2700X with PBO Enabled and -0.0750 V Offset
	\item	Cooling: AMD Wraith Prism (Box Cooler) with Thermal Grizzly Carbonaut TIM
	\item	Motherboard: MSI B450 Mortar
	\item	Memory: Corsair 2x8 GB (16 GB) @ 3000 MHz 16-17-17-35
	\item	PSU: Seasonic FOCUS Plus 650 Gold
	\item	OS: Windows 10 Home 64-bit 2004
	\item	Case: Cooler Master MasterBox Q300L +2 120 mm front pull fans
	\item	GPU: \href{http://www.overclockersclub.com/reviews/nvidia_geforce_rtx2060_founders_edition/}{NVIDIA RTX 2060}
\end{itemize}

With that covered, time to get to the body of this article, starting with the Python script that manages the entire process. In total there are six scripts, with four being R scripts that manage the data collected, and the last one is also a Python script with the purpose of renaming the graph files with code numbers for easier upload on Overclockers Club.
